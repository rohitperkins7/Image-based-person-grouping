!pip install faiss-gpu
import os
import numpy as np
import zipfile
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.cluster import DBSCAN
from torchvision import models, transforms
from PIL import Image
import torch
import faiss
import io

# Load pre-trained model (e.g., ResNet50 without the classification head)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
resnet50 = models.resnet50(pretrained=True)
model = torch.nn.Sequential(*list(resnet50.children())[:-1])  # Remove the classification layer
model = model.to(device)

# Transform for input images
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

# Unzip dataset and read image data
zip_path = "/content/tango-cv-assessment-dataset.zip"
with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    image_names = [name for name in zip_ref.namelist() if name.endswith(('.jpg', '.png'))]
    image_data = [zip_ref.read(name) for name in image_names]


# Step 1: Feature Extraction
def extract_features(image_data, model, transform, batch_size=32):
    """Extracts feature vectors for images using a pre-trained model."""
    model.eval()
    features = []
    with torch.no_grad():
        for i in range(0, len(image_data), batch_size):
            batch_data = image_data[i:i+batch_size]
            images = [transform(Image.open(io.BytesIO(data)).convert('RGB')) for data in batch_data]
            images = torch.stack(images).to(device)
            outputs = model(images)
            outputs = outputs.view(outputs.size(0), -1)  # Flatten the feature maps
            features.append(outputs.cpu().numpy())
            print(f"Processed {i+len(batch_data)}/{len(image_data)} images")
    return np.vstack(features)

# Feature extraction
print("Extracting features...")
features = extract_features(image_data, model, transform)

# Step 2: Clustering
def cluster_features(features, eps=0.5, min_samples=5):
    """Improved clustering with scaling and dimensionality reduction."""
    print("Scaling features...")
    features_scaled = StandardScaler().fit_transform(features)  # Feature scaling

    print("Reducing dimensionality...")
    pca = PCA(n_components=50)  # Reduce dimensionality before clustering
    features_reduced = pca.fit_transform(features_scaled)

    print("Clustering features...")
    clustering = DBSCAN(eps=eps, min_samples=min_samples, metric='cosine').fit(features_reduced)
    print("Clustering completed.")
    return clustering.labels_

# Clustering
labels = cluster_features(features, eps=0.5, min_samples=15)

# Save results
print("Saving clustering results...")
np.save("features.npy", features)
np.save("labels.npy", labels)


# Step 3: Retrieval System
def retrieve_images(query_image_data, features, labels, model, transform, query_features):
    """Retrieve all images in the same cluster as the query image."""
    # query_features = extract_features([query_image_data], model, transform)
    cluster_id = labels[np.argmax(cosine_similarity(features, query_features))]
    return [i for i, label in enumerate(labels) if label == cluster_id]

retrieved_features = features[retrieved_indices]
dimension = retrieved_features.shape[1]  # Dimension of the feature vectors
index = faiss.IndexFlatL2(dimension)  # Create a Faiss index for Euclidean distance
index.add(retrieved_features)  # Add the retrieved features to the index
D, I = index.search(query_features, len(retrieved_features))  # Search for nearest neighbors
sorted_indices = I[0]  # Get the indices of the nearest neighbors
re_ranked_images = [retrieved_images[i] for i in sorted_indices]

print("Re-ranked retrieved images:")
print(re_ranked_images)

# Step 4: Show Similar Images
def show_image_from_zip(zip_path, image_name):
    """Displays an image from a zip file given the zip path and image name."""
    # Open the zip file and read the specified image
    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        if image_name in zip_ref.namelist():
            # Read the image data
            image_data = zip_ref.read(image_name)
        else:
            print(f"Image '{image_name}' not found in the zip file.")
            return

    # Open and display the image
    image = Image.open(io.BytesIO(image_data))
    plt.imshow(image)
    plt.title(f"Image: {image_name}")
    plt.axis('off')  # Hide axes for better visualization
    plt.show()

# Retrieval example

query_image_name = "tango-cv-assessment-dataset/0002_c1s2_064446_00.jpg"
with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    query_image_data = zip_ref.read(query_image_name)
query_features = extract_features([query_image_data], model, transform) # Define query_features here

retrieved_indices = retrieve_images(query_image_data, features, labels, model, transform, query_features)
retrieved_images = [image_names[i] for i in retrieved_indices]


print("Query Image:")
show_image_from_zip(zip_path, query_image_name)

print("Retrieved Images:")
for img in re_ranked_images[:100]:
    show_image_from_zip(zip_path, img)

